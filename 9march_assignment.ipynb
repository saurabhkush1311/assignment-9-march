{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b8c248-4ab1-431d-859f-ad2eb8311d04",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98ffa5-917b-4fca-9e31-fb82670cdf32",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fcb76a-2f25-42ef-a258-8e5e6e86df14",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40332f81-0bc0-4c88-8d44-6e45de541868",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c333b0c-cc5f-46ea-8e73-4693fc0b8b20",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ee16b-d407-4790-aa03-e8e18f337e09",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e9862-d679-41ea-bf83-341a16c210ba",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a150682-7ad5-46a6-a915-f80abaf51514",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c7317-1d11-4fd7-82b3-f4f379df6030",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f8de9-b962-4d72-b189-49cbe711731a",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6e34aa-26f2-4a79-b512-ba6d1e9e83b3",
   "metadata": {},
   "source": [
    "Answer1\n",
    "\n",
    "The PMF is used for discrete random variables. It gives the probability of the random variable taking on a specific value. In other words, it maps each possible value of the discrete random variable to its associated probability. The sum of all probabilities in the PMF is equal to 1.\n",
    "Let's consider the random variable X representing the outcome of rolling a fair six-sided die. The possible values of X are {1, 2, 3, 4, 5, 6}, and since the die is fair, each outcome has an equal probability of 1/6. The PMF for X would be:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668f4bd-0575-456b-9c0d-5927375dd46d",
   "metadata": {},
   "source": [
    "Answer2\n",
    "\n",
    "The Cumulative Density Function (CDF) is a function used to describe the cumulative probability distribution of a random variable. It gives the probability that the random variable takes on a value less than or equal to a specific value. In other words, the CDF provides the cumulative probability up to a given point along the range of values of the random variable.\n",
    "\n",
    "\n",
    "Example of CDF:\n",
    "Let's consider the random variable X representing the outcome of rolling a fair six-sided die. The possible values of X are {1, 2, 3, 4, 5, 6}, and since the die is fair, each outcome has an equal probability of 1/6. The CDF for X would be:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "For x = 1:\n",
    "F(1) = P(X ≤ 1) = P(X = 1) = 1/6\n",
    "\n",
    "For x = 2:\n",
    "F(2) = P(X ≤ 2) = P(X = 1 or X = 2) = 1/6 + 1/6 = 1/3\n",
    "\n",
    "For x = 3:\n",
    "F(3) = P(X ≤ 3) = P(X = 1 or X = 2 or X = 3) = 1/6 + 1/6 + 1/6 = 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f1489-e29b-4d70-a8dd-6e50bdb7c7f1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Answer3\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is one of the most widely used probability distributions in statistics. It is often used as a model in situations where data tend to cluster around a central value with fewer observations at the extreme values. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Height of Adult Humans: The heights of adult humans tend to follow approximately a normal distribution. The majority of people are of average height, with fewer individuals at very tall or very short heights.\n",
    "\n",
    "Test Scores: In standardized tests, such as IQ tests or college entrance exams, the scores often approximate a normal distribution. Most test-takers score around the average, with fewer scores at the high and low ends.\n",
    "\n",
    "Measurement Errors: In many scientific measurements, errors can follow a normal distribution. For instance, the errors in measuring the length of an object or the volume of a liquid may be normally distributed around the true value.\n",
    "\n",
    "Biological Traits: Various biological traits, such as weight, blood pressure, or reaction times, often exhibit normal distribution characteristics in a population.\n",
    "\n",
    "Parameters of the Normal Distribution:\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). These parameters determine the position and spread of the distribution, respectively.\n",
    "\n",
    "Mean (μ): The mean of the normal distribution is its central value. It represents the peak or center of the bell-shaped curve. Shifting the mean to the right or left will move the entire distribution along the horizontal axis.\n",
    "\n",
    "Standard Deviation (σ): The standard deviation measures the spread or dispersion of the data points around the mean. A larger standard deviation results in a wider and flatter curve, indicating greater variability in the data. Conversely, a smaller standard deviation yields a narrower and taller curve, indicating less variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c5def-ec1c-49fa-b0e4-80fe37b1f363",
   "metadata": {},
   "source": [
    "Answer4\n",
    "\n",
    "The normal distribution is of paramount importance in statistics and probability theory due to several key reasons:\n",
    "\n",
    "Central Limit Theorem: One of the most significant properties of the normal distribution is its relationship with the Central Limit Theorem. According to this theorem, the sum (or average) of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the underlying distribution of the individual variables. This makes the normal distribution a fundamental tool in many statistical analyses.\n",
    "\n",
    "Ease of Analysis: The normal distribution has well-defined mathematical properties, which makes it analytically tractable. Calculations and statistical inferences with the normal distribution are relatively straightforward compared to other distributions, making it a convenient choice in many applications.\n",
    "\n",
    "Statistical Inference: The normal distribution is frequently used in statistical inference, hypothesis testing, and confidence interval estimation. Many statistical tests, such as t-tests and z-tests, are based on the assumption of normality.\n",
    "\n",
    "Data Approximation: In practice, many real-world phenomena exhibit behavior that can be reasonably approximated by a normal distribution. While data might not be exactly normally distributed, they can often be close enough to justify using the normal distribution as an approximation.\n",
    "\n",
    "Now, let's look at a few real-life examples where the normal distribution is commonly observed:\n",
    "\n",
    "Height of Adult Humans: As mentioned earlier, the heights of adult humans often follow a normal distribution, with most people clustered around the average height and fewer individuals at the extremes (very tall or very short).\n",
    "\n",
    "Exam Scores: In standardized exams, such as SAT or GRE, the scores of test-takers typically form a normal distribution. The majority of scores center around the mean score, and fewer students achieve exceptionally high or low scores.\n",
    "\n",
    "Measurement Errors: In scientific experiments and measurements, errors can often be modeled by a normal distribution. For example, when measuring the weight of identical objects multiple times, the errors in the measurements are expected to follow a normal distribution around the true weight.\n",
    "\n",
    "IQ Scores: IQ (intelligence quotient) scores are often distributed approximately normally in the population. Most people have an average IQ, while fewer individuals have exceptionally high or low IQs.\n",
    "\n",
    "Reaction Times: The time taken by individuals to react to a stimulus, such as in a psychology experiment, can often be modeled by a normal distribution.\n",
    "\n",
    "Noise in Electronics: In electronic circuits and communication systems, the noise introduced by various components tends to follow a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf5297-f128-4de3-9a00-600fc5ae9354",
   "metadata": {},
   "source": [
    "Answer5\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that models a single experiment with two possible outcomes: success (usually denoted by 1) or failure (usually denoted by 0). The outcomes are mutually exclusive, meaning that only one of them can occur in a single trial. The probability of success is denoted by 'p', and the probability of failure (1 - p) is denoted by 'q', where 0 ≤ p ≤ 1.\n",
    "\n",
    "Example of Bernoulli Distribution:\n",
    "An example of a Bernoulli distributed random variable could be the outcome of a single coin toss, where we define \"Heads\" as success (1) and \"Tails\" as failure (0). If the coin is fair (equally likely to land on either side), the probability of getting Heads (p) is 0.5, and the probability of getting Tails (q) is also 0.5.\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "Number of Trials:\n",
    "\n",
    "Bernoulli Distribution: Represents a single trial or experiment with two possible outcomes.\n",
    "Binomial Distribution: Represents the number of successes in a fixed number of independent Bernoulli trials.\n",
    "Number of Possible Outcomes:\n",
    "\n",
    "Bernoulli Distribution: Has two possible outcomes: success (1) or failure (0).\n",
    "Binomial Distribution: The number of successes can take on any value from 0 to the total number of trials.\n",
    "Parameters:\n",
    "\n",
    "Bernoulli Distribution: Has one parameter, 'p', which is the probability of success in a single trial.\n",
    "Binomial Distribution: Has two parameters, 'n' and 'p', where 'n' is the number of trials and 'p' is the probability of success in a single trial.\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "Bernoulli Distribution: The PMF for Bernoulli is given by P(X = x) = p^x * (1 - p)^(1-x) for x = 0 or 1.\n",
    "Binomial Distribution: The PMF for Binomial is given by P(X = k) = (n choose k) * p^k * (1 - p)^(n-k) for k = 0, 1, 2, ..., n.\n",
    "Number of Trials and Independence:\n",
    "\n",
    "Bernoulli Distribution: Represents a single trial, so there is no notion of multiple trials or independence.\n",
    "Binomial Distribution: Represents the sum of successes in 'n' independent Bernoulli trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f8ba7-9637-45d2-9c78-b3f7d98876c3",
   "metadata": {},
   "source": [
    "Answer6\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "X is the value we want to find the Z-score for (in this case, X = 60).\n",
    "μ is the mean of the dataset (μ = 50).\n",
    "σ is the standard deviation of the dataset (σ = 10).\n",
    "Z = (60 - 50) / 10\n",
    "Z = 1\n",
    "P(X > 60) = 1 - P(X ≤ 60)\n",
    "P(X > 60) = 1 - 0.8413\n",
    "P(X > 60) = 0.1587\n",
    "\n",
    "So, the probability that a randomly selected observation from the dataset is greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28e610-c301-4d79-b35a-901009360b08",
   "metadata": {},
   "source": [
    "Answer7\n",
    "\n",
    "For a continuous uniform distribution over the interval [a, b], the probability density function (PDF) is defined as:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "\n",
    "where:\n",
    "\n",
    "f(x) is the probability density function.\n",
    "a is the minimum value of the range.\n",
    "b is the maximum value of the range.\n",
    "For a discrete uniform distribution over the set {a, a+1, a+2, ..., b}, the probability mass function (PMF) is defined as:\n",
    "\n",
    "P(X = x) = 1 / (b - a + 1) for a ≤ x ≤ b\n",
    "\n",
    "where:\n",
    "\n",
    "P(X = x) is the probability that the random variable X takes the value x.\n",
    "a is the minimum value of the range.\n",
    "b is the maximum value of the range.\n",
    "\n",
    "Example of Uniform Distribution:\n",
    "Let's consider an example of a continuous uniform distribution representing the rolling of a fair six-sided die. In this case, the range of possible outcomes is [1, 6]. Each face of the die has an equal probability of 1/6 of landing face-up.\n",
    "\n",
    "The probability density function (PDF) for the rolling of the die is:\n",
    "\n",
    "f(x) = 1 / (6 - 1) for 1 ≤ x ≤ 6\n",
    "\n",
    "f(x) = 1/6 for 1 ≤ x ≤ 6\n",
    "\n",
    "In this example, the uniform distribution ensures that each outcome (1, 2, 3, 4, 5, 6) is equally likely, and there are no preferences or biases towards any particular face of the die."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070ae47-26b7-42ff-93e3-d6f3fd114298",
   "metadata": {},
   "source": [
    "Answer8:\n",
    "    \n",
    "The z-score, also known as the standard score, is a measure that indicates how many standard deviations a data point is away from the mean of a dataset. It is used to standardize or normalize data, allowing comparisons between data points from different distributions and helping to identify outliers or extreme values.\n",
    "The formula to calculate the z-score for a data point 'X' in a dataset with mean 'μ' and standard deviation 'σ' is given by:\n",
    "\n",
    "z = (X - μ) / σ\n",
    "\n",
    "where:\n",
    "\n",
    "'z' is the z-score of the data point 'X'.\n",
    "'X' is the individual data point.\n",
    "'μ' is the mean of the dataset.\n",
    "'σ' is the standard deviation of the dataset.\n",
    "\n",
    "Importance of the Z-Score:\n",
    "The z-score is important for several reasons:\n",
    "\n",
    "Standardization and Comparison: The z-score standardizes data by transforming it to a common scale with a mean of 0 and a standard deviation of 1. This allows for easy comparison and analysis of data points from different distributions or datasets.\n",
    "\n",
    "Identification of Outliers: Z-scores help identify outliers or extreme values in a dataset. Data points with z-scores significantly larger or smaller than zero are considered outliers, as they deviate significantly from the mean.\n",
    "\n",
    "Probability Estimation: Z-scores are used to estimate probabilities associated with specific data points in a normal distribution. By converting data into z-scores, one can use standard normal distribution tables or statistical software to find the probabilities related to those values.\n",
    "\n",
    "Hypothesis Testing: In statistical hypothesis testing, z-scores play a crucial role. They are used to calculate test statistics in cases where the sample size is large, and the sampling distribution can be approximated by a normal distribution.\n",
    "\n",
    "Data Transformation: The z-score transformation is commonly used in data preprocessing and feature scaling for various machine learning algorithms. It ensures that features with different scales do not dominate the analysis or lead to biased results.\n",
    "\n",
    "Quality Control and Process Monitoring: In industries, z-scores are used in statistical process control to detect deviations from standard norms and identify potential quality issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c6156-38dc-4ac5-a2e6-f833ac5c20fc",
   "metadata": {},
   "source": [
    "Answer9:\n",
    "\n",
    "The Central Limit Theorem (CLT) is a fundamental principle in statistics that states that the sampling distribution of the mean (or sum) of a large number of independent and identically distributed (i.i.d.) random variables will be approximately normally distributed, regardless of the shape of the original population's distribution. In simpler terms, when we take a large enough sample from any population and calculate the sample means, the distribution of these sample means will tend to follow a normal distribution.\n",
    "\n",
    "The Central Limit Theorem is a powerful concept with several key points of significance:\n",
    "\n",
    "Approximation of the Normal Distribution: The CLT allows us to use the normal distribution to approximate the behavior of sample means or sums, even if the original population is not normally distributed. This is particularly useful because the normal distribution has well-defined properties and is mathematically tractable, making statistical analyses much simpler.\n",
    "\n",
    "Sample Size Independence: The CLT does not depend on the shape of the population distribution; it only requires the sample size to be sufficiently large. This is particularly valuable because it enables us to apply the CLT in various real-world scenarios, regardless of the underlying distribution of the population.\n",
    "\n",
    "Basis for Statistical Inference: The Central Limit Theorem forms the foundation for many statistical inference techniques, including confidence intervals and hypothesis testing. It allows us to make probabilistic statements about sample means, even when population parameters are unknown.\n",
    "\n",
    "Pooling of Sample Data: The CLT is often used to justify the pooling of data from different samples or studies. When the sample sizes are large, we can assume that the means from different samples are approximately normally distributed, making it easier to combine and analyze data.\n",
    "\n",
    "Sample Size Determination: The Central Limit Theorem guides researchers in determining appropriate sample sizes for their studies. By ensuring that sample sizes are large enough, they can be more confident that sample means will follow a normal distribution.\n",
    "\n",
    "Applied in Many Fields: The CLT is widely used across various disciplines, including psychology, biology, economics, engineering, and social sciences. It is a cornerstone of statistical analysis and research in these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1228c78-9590-4305-9316-41ea8e6483f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer10\n",
    "\n",
    "The Central Limit Theorem (CLT) is a fundamental statistical concept that describes the behavior of the sampling distribution of the sample mean (or sum) for a large number of independent and identically distributed random variables, regardless of the shape of the original population distribution. The theorem relies on certain assumptions to hold true. Here are the main assumptions of the Central Limit Theorem:\n",
    "\n",
    "Independence: The individual observations in the sample must be independent of each other. In other words, the value of one observation should not be influenced by or related to the values of other observations in the sample.\n",
    "\n",
    "Identical Distribution: Each observation in the sample should be drawn from the same probability distribution. This assumption ensures that the random variables have the same mean (μ) and standard deviation (σ).\n",
    "\n",
    "Finite Variance: The random variables being sampled should have a finite variance (σ^2). If the variance is infinite, the Central Limit Theorem may not hold.\n",
    "\n",
    "Sample Size: The sample size (n) should be sufficiently large. There is no fixed rule for what constitutes a \"large\" sample size, but as a general guideline, a sample size of at least 30 is often considered sufficient for the Central Limit Theorem to apply. However, in some cases, even smaller sample sizes can be acceptable depending on the population distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
